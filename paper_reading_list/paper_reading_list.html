
<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="resource/html.css" type="text/css">
<link rel="shortcut icon" href="resource/my_photo.jpg">
<title>Paper Reading List</title>
<meta name="description" content="Paper Reading List">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<div id="layout-content" style="margin-top:25px">
<body>

<h1 id="top">Artificial Intelligence</h1>
<p class="larger"><b><font color='#D93053'>77</font> papers on  Artificial Intelligence.</b></p>
<p>Curated by <a href="https://junkunyuan.github.io/">Junkun Yuan</a>.</p>

<p><font color=#B0B0B0>Last updated on July 29, 2025 at 13:34 (UTC+8).</font></p>
<hr><p id="table" class="larger"><b>Table of contents:</b></p><ul><li><a class="no_dec" href=coding.html>Coding and Engineering</a> &nbsp; <font color=#B0B0B0>Tools used to build AI systems.</font></li><li><a class="no_dec" href=visual_generation.html>Visual Generation</a> (62 papers) &nbsp; <font color=#B0B0B0>Generate visual signals (e.g., images, video, and 3D).</font></li><li><a class="no_dec" href=multimodal_understanding.html>Multimodal Understanding</a> (11 papers) &nbsp; <font color=#B0B0B0>Understand and reason by integrating multiple modalities (e.g., text, images, video, audio).</font></li><li><a class="no_dec" href=native_multimodal_generation.html>Native Multimodal Generation</a> (4 papers) &nbsp; <font color=#B0B0B0>Integrate and generate multiple modalities (e.g., text, images, video, audio) within a unified model.</font></li></ul>
</body>
</html>
