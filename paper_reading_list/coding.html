
<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="resource/html.css" type="text/css">
<link rel="shortcut icon" href="resource/my_photo.jpg">
<title>Paper Reading List</title>
<meta name="description" content="Paper Reading List">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<div id="layout-content" style="margin-top:25px">
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.24.1/prism.min.js"></script>
                <link href="https://cdn.jsdelivr.net/npm/prismjs@1.24.1/themes/prism.css" rel="stylesheet">
                <script src="https://cdn.jsdelivr.net/npm/prismjs@1.24.1/components/prism-bash.min.js"></script>
                <script src="https://cdn.jsdelivr.net/npm/prismjs@1.24.1/components/prism-python.min.js"></script>
                <body>

<h1 id="top">Coding and Engineering</h1>
<p class="huger"><b> Coding and Engineering.</b></p>
<p>Curated by <a href="https://junkunyuan.github.io/">Junkun Yuan</a>.</p>
<p>Click <a href="paper_reading_list.html">here</a> to go back to main contents.</p>
<p><font color=#B0B0B0>Last updated on July 31, 2025 at 23:08 (UTC+8).</font></p>
<hr><p id='table' class="huger"><b>Table of contents:</b></p><ul><li><a class="no_dec larger" id="torch & torchvision" href="#torch & torchvision-table"><b>torch & torchvision</b></a></li><p><a class="no_dec" href="#data transformstorch & torchvision"><font color=#404040>data transforms</font></a> <font color=#B0B0B0>&nbsp;|&nbsp;</font> <a class="no_dec" href="#data loadertorch & torchvision"><font color=#404040>data loader</font></a> <font color=#B0B0B0>&nbsp;|&nbsp;</font> <a class="no_dec" href="#moduletorch & torchvision"><font color=#404040>module</font></a> <font color=#B0B0B0>&nbsp;|&nbsp;</font> <a class="no_dec" href="#optimizertorch & torchvision"><font color=#404040>optimizer</font></a></p></ul><h2 id="torch & torchvision-table"><a class="no_dec" href="#torch & torchvision">torch & torchvision</a></h2>
            <p class="little_split" id='data transformstorch & torchvision'></p>
            <div style="border-left: 14px solid #ADDEFF; padding-left: 10px">
            <div style="height: 0.3em;"></div>
            <p class="paper_title" onclick="toggleTable('data transforms-torch & torchvision-details')"><i>Data Transforms</i></p>
            
            
            <p class="paper_detail"><b> data transforms</b>  &nbsp;&nbsp;|&nbsp;&nbsp; <a href="https://docs.pytorch.org/vision/stable/transforms.html">docs</a> &nbsp; <font color=#D0D0D0></font></p>
            
            
            <div id='data transforms-torch & torchvision-details' class="info_detail">
                <hr class="dashed">
                <p><font color=#202020>It includes tools to transform and augment data: <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html?highlight=transforms+resize#torchvision.transforms.Resize">Resize</a>, <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip">RandomHorizontalFlip</a>, <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html?highlight=totensor#torchvision.transforms.ToTensor">ToTensor</a>, <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose">Compose</a>, <a href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize">Normalize</a>.</font></p>
                
                <p>
<pre>
<code class="language-python">
from torchvision import transforms
from torchvision.transforms.InterpolationMode import BILINEAR, NEAREST, BICUBIC 

## --------------------------------------------------------------------------------
## Geometry: Resize
## --------------------------------------------------------------------------------
size = /  # *** sequence or int. For example (512, 768)
interpolation = BILINEAR  # InterpolationMode
max_size = None  # int. Maximum allowed for the longer edge, supported if `size` is int
antialias = True  # bool. Apply antialiasing, only under bilinear or bicubic modes

trans = transforms.Resize(size, interpolation, max_size, antialias)
image_trans = trans(image)  # PIL Image => PIL Image or Tensor => Tensor
## --------------------------------------------------------------------------------

## --------------------------------------------------------------------------------
## Geometry: RandomHorizontalFlip
## --------------------------------------------------------------------------------
p = 0.5  # *** float. Probability to flip image

trans = <b>transforms.RandomHorizontalFlip</b>(p)
image_trans = trans(image)  # PIL Image => PIL Image or Tensor => Tensor
## --------------------------------------------------------------------------------

## --------------------------------------------------------------------------------
## Conversion: ToTensor
## --------------------------------------------------------------------------------
## Input: PIL Image / numpy.ndarray (np.uint8) of shape (HxWxC) in the range [0, 255]
## Output: torch.FloatTensor of shape (CxHxW) in the range (0.0, 1.0)
## Other inputs: only apply type transform
trans = <b>transforms.ToTensor</b>()
image_trans = trans(image)  # PIL Image / ndarray => Tensor
## --------------------------------------------------------------------------------

## --------------------------------------------------------------------------------
## Composition: Compose
## --------------------------------------------------------------------------------
transforms = /  # *** list of Transform objects

trans = <b>transforms.Compose</b>(transforms)
image_trans = trans(image)  # PIL Image / ndarray / Tensor => Tensor
## --------------------------------------------------------------------------------

## --------------------------------------------------------------------------------
## Miscellaneous: Normalize
## --------------------------------------------------------------------------------
mean = /  # *** sequence. Means for each channel.
std = /  # *** sequence. Standard deviations for each channel.
inplace = False  # bool. Bool to make this operation in-place.

trans = <b>transforms.Normalize</b>(mean, std, inplace)
image_trans = trans(image)  # Tensor => Tensor
## --------------------------------------------------------------------------------
</code>
</pre>
</p>
            </div>
            <div style="height: 0.05em;"></div>
            </div>
            <p class="little_split"></p>
            
            <p class="little_split" id='data loadertorch & torchvision'></p>
            <div style="border-left: 14px solid #ADDEFF; padding-left: 10px">
            <div style="height: 0.3em;"></div>
            <p class="paper_title" onclick="toggleTable('data loader-torch & torchvision-details')"><i>Data Loader</i></p>
            
            
            <p class="paper_detail"><b> data loader</b>  &nbsp;&nbsp;|&nbsp;&nbsp; <a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">docs</a> &nbsp; <font color=#D0D0D0></font></p>
            
            
            <div id='data loader-torch & torchvision-details' class="info_detail">
                <hr class="dashed">
                <p><font color=#202020>It includes tools for data loading: <a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">DataLoader</a>.</font></p>
                
                <p>
<pre>
<code class="language-python">
import torch
from torch.utils.data import DataLoader, Dataset, Sampler

## --------------------------------------------------------------------------------
## DataLoader
## --------------------------------------------------------------------------------
dataset = /  # *** Dataset
batch_size = 1  # *** int. Number of samples per batch.
shuffle = False  # *** bool. If True, have the data shuffled at every epoch
sampler = None  # Sampler or Iterable. Define how to draw samples
batch_sampler = None  # Sampler or Iterable. customize sampling by giving indices
num_workers = 0  # *** int. Number of subprocesses to use for data loading
collate_fn = None  # Callable. Merge a list of samples to form a batch of tensors.
pin_memory = False  # *** bool. If True, copy Tensors into CUDA pinned memory.
drop_last = False  # *** bool. If True, drop the last incomplete batch
timeout = 0  # numeric. If positive, set timeout for collecting a batch from workers.
worker_init_fn = None  # Callable. If not None, it will be called (worker id as input) 
multiprocessing_context = None  # str or multiprocessing.context.BaseContext.
generator = None  # torch.Generator. If not None, it will be used by sampler & workers
prefetch_factor = None  # int. Default = None if num_workers == 0 else 2
persistent_workers = False  # bool. If True, workers will not shut down after an epoch.
pin_memory_device = ""  # str. The device to pin memory
in_order = True  # bool. If False, it will not enforce batches to return in order

data_loader = DataLoader(
    dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, 
    pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, 
    generator, prefetch_factor, persistent_workers, pin_memory_device, in_order
)
## --------------------------------------------------------------------------------
</code>
</pre>
</p>
            </div>
            <div style="height: 0.05em;"></div>
            </div>
            <p class="little_split"></p>
            
            <p class="little_split" id='moduletorch & torchvision'></p>
            <div style="border-left: 14px solid #ADDEFF; padding-left: 10px">
            <div style="height: 0.3em;"></div>
            <p class="paper_title" onclick="toggleTable('module-torch & torchvision-details')"><i>Module</i></p>
            
            
            <p class="paper_detail"><b> module</b>  &nbsp;&nbsp;|&nbsp;&nbsp; <a href="https://docs.pytorch.org/docs/stable/nn.html">docs</a> &nbsp; <font color=#D0D0D0></font></p>
            
            
            <div id='module-torch & torchvision-details' class="info_detail">
                <hr class="dashed">
                <p><font color=#202020>It includes tools to build neural networks: <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d">Conv2d</a>, <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#conv3d">Conv3d</a>.</font></p>
                
                <p>
<pre>
<code class="language-python">
import torch
from torch.nn import Conv2d, Conv3d

## --------------------------------------------------------------------------------
## Conv2d
## --------------------------------------------------------------------------------
in_channels = /  # *** int. Number of channels in the input
out_channels = /  # *** int. Number of channels in the output
kernel_size = /  # *** int, tuple. Size of convolving kernel
stride = 1  # *** int, tuple. Stride of convolution
padding = 0  # int, tuple, str. Padding added to all four sides of the input
dilation = 1  # int, tuple. Spacing between kernel elements
groups = 1  # int. Number of blocked connections from input channels to output
bias = True  # bool. If True, add a learnable bias to the output
padding_mode = "zeros"  # str. "zeros", "reflect", "replicate", or "circular"
device = None # str, torch.device. 
dtype = None # torch.dtype.

## Weight. Shape: [out_channels, in_channels/groups, k_size[0], k_size[1]]
## Bias. Shape: [out_channels,]
conv2d = Conv2d(
    in_channels, out_channels, kernel_size, stride, padding, dilation, groups, 
    bias, padding_mode, device, dtype
)
## [B, C, H_in, W_in] => [B, C, H_out, W_out]
## H_out = [(H_in + 2*padding[0] - dilation[0]*(kernel[0]-1)-1) / stride[0] + 1]
## W_out = [(W_in + 2*padding[1] - dilation[1]*(kernel[1]-1)-1) / stride[1] + 1]
y = conv2d(x)  # Tensor => Tensor
## --------------------------------------------------------------------------------

## --------------------------------------------------------------------------------
## Conv3d
## --------------------------------------------------------------------------------
in_channels = /  # *** int. Number of channels in the input
out_channels = /  # *** int. Number of channels in the output
kernel_size = /  # *** int, tuple. Size of convolving kernel
stride = 1  # *** int, tuple. Stride of convolution
padding = 0  # int, tuple, str. Padding added to all six sides of the input
dilation = 1  # int, tuple. Spacing between kernel elements
groups = 1  # int. Number of blocked connections from input channels to output
bias = True  # bool. If True, add a learnable bias to the output
padding_mode = "zeros"  # str. "zeros", "reflect", "replicate", or "circular"
device = None # str, torch.device. 
dtype = None # torch.dtype.

## Weight. Shape: [out_channels, in_channels/groups, k_size[0], k_size[1], k_size[2]]
## Bias. Shape: [out_channels,]
conv2d = Conv2d(
    in_channels, out_channels, kernel_size, stride, padding, dilation, groups, 
    bias, padding_mode, device, dtype
)
## [B, C, D_in, H_in, W_in] => [B, C, D_out, H_out, W_out]
## D_out = [(D_in + 2*padding[0] - dilation[0]*(kernel[0]-1)-1) / stride[0] + 1]
## H_out = [(H_in + 2*padding[1] - dilation[1]*(kernel[1]-1)-1) / stride[1] + 1]
## W_out = [(W_in + 2*padding[2] - dilation[2]*(kernel[2]-1)-2) / stride[2] + 1]
y = conv2d(x)  # Tensor => Tensor
## --------------------------------------------------------------------------------
</code>
</pre>
</p>
            </div>
            <div style="height: 0.05em;"></div>
            </div>
            <p class="little_split"></p>
            
            <p class="little_split" id='optimizertorch & torchvision'></p>
            <div style="border-left: 14px solid #ADDEFF; padding-left: 10px">
            <div style="height: 0.3em;"></div>
            <p class="paper_title" onclick="toggleTable('optimizer-torch & torchvision-details')"><i>Optimizer</i></p>
            
            
            <p class="paper_detail"><b> optimizer</b>  &nbsp;&nbsp;|&nbsp;&nbsp; <a href="https://docs.pytorch.org/docs/stable/optim.html">docs</a> &nbsp; <font color=#D0D0D0></font></p>
            
            
            <div id='optimizer-torch & torchvision-details' class="info_detail">
                <hr class="dashed">
                <p><font color=#202020>It includes tools for building optimization algorithms: <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.AdamW.html#torch.optim.AdamW.step">AdamW</a>.</font></p>
                
                <p>
<pre>
<code class="language-python">
from torch.optim import AdamW

## --------------------------------------------------------------------------------
## AdamW
## --------------------------------------------------------------------------------
params = /  # *** iterable. Parameters / named_parameters / parameter groups to optimize
lr = 0.001  # *** float, Tensor. Learning rate
betas = (0.9, 0.999)  # tuple. For computing running averages of gradients & squares
eps = 1e-08  # float. Added to denominator to improve numerical stability
weight_decay = 0.01  # float. Weight decay coefficient
amsgrad = False # bool. Whether to use AMSGrad 
maximize = False  # bool. Maximize the objective with respect to params, not minimize
foreach = None  # bool. Whether foreach implementation of optimizer is used.
capturable = False  # bool. Pass True can impair ungraphed performance
differentiable = False  # bool. Whether has gradient
fused = None  # bool. Whether use the fused implementation

adam_optim = AdamW(
    params, lr, betas, eps, weight_decay, amsgrad, maximize, 
    foreach, capturable, differentiable, fused
)
## --------------------------------------------------------------------------------
</code>
</pre>
</p>
            </div>
            <div style="height: 0.05em;"></div>
            </div>
            <p class="little_split"></p>
            
    <script>
        function toggleTable(tableId) {
            const container = document.getElementById(tableId);
            const button = container.previousElementSibling;
            const isVisible = window.getComputedStyle(container).display !== 'none';
            if (!isVisible) {
                const images = container.querySelectorAll('img');
                images.forEach(img => {
                    if (img.dataset.src !== '') {
                        img.src = img.dataset.src;
                    }
                });
                container.style.display = 'block';
            } else {
                container.style.display = 'none';
                
            }
        }
    </script>

    <button id="backToTop" title="back to top">↑</button>
    <script>
        const button = document.getElementById("backToTop");
        window.addEventListener("scroll", () => {
        if (document.documentElement.scrollTop > 300) {
            button.style.display = "block";
        } else {
            button.style.display = "none";
        }
        });

        function updateButtonPosition() {
        const bodyRect = document.body.getBoundingClientRect();
        const windowWidth = window.innerWidth;
        const rightOffset = Math.max((windowWidth - bodyRect.width) / 2, 10);
        button.style.right = rightOffset + "px";
        }

        window.addEventListener("resize", updateButtonPosition);
        window.addEventListener("load", updateButtonPosition);

        button.addEventListener("click", () => {
        window.scrollTo({ top: 0, behavior: 'smooth' });
        });
    </script>
    
</body>
</html>
